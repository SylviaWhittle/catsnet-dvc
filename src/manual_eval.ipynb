{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from unet import iou_loss, dice_loss, bce_loss\n",
    "\n",
    "# get binary crossentropy loss\n",
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a model\n",
    "print(list(Path(\"../models/\").iterdir()))\n",
    "model = tf.keras.models.load_model(\n",
    "    \"../models/catsnet_model.h5\", custom_objects={\"iou_loss\": iou_loss, \"dice_loss\": dice_loss}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "\n",
    "data_dir = Path(\"../data/all_data/\")\n",
    "assert data_dir.exists()\n",
    "\n",
    "# Find the indexes of all the image files in the format of image_<index>.npy\n",
    "image_indexes = [int(re.search(r\"\\d+\", file.name).group()) for file in data_dir.glob(\"image_*.npy\")]\n",
    "mask_indexes = [int(re.search(r\"\\d+\", file.name).group()) for file in data_dir.glob(\"mask_*.npy\")]\n",
    "\n",
    "# Get a test dataset of 0.2 * size of the dataset\n",
    "test_size = int(0.2 * len(image_indexes))\n",
    "print(f\"Test size: {test_size}\")\n",
    "\n",
    "test_indexes = np.random.choice(image_indexes, test_size, replace=False)\n",
    "print(f\"Test indexes: {test_indexes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_loss_simple(y_true, y_pred, smooth=1e-7):\n",
    "    \"\"\"Intersection over Union loss function for a single image.\"\"\"\n",
    "\n",
    "    # Formula:\n",
    "    # IoU = (|X & Y|)/ (|X or Y|)\n",
    "\n",
    "    # Non optimal but easy to understand version:\n",
    "    # true_pos = tf.reduce_sum(y_true * y_pred)\n",
    "    # false_pos = tf.reduce_sum(y_pred) - true_pos\n",
    "    # false_neg = tf.reduce_sum(y_true) - true_pos\n",
    "    # return 1 - (true_pos + smooth) / (true_pos + false_pos + false_neg + smooth)\n",
    "\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    assert y_true.dtype == bool\n",
    "\n",
    "    # convert to float\n",
    "    y_true_float = tf.cast(y_true, tf.float32)\n",
    "\n",
    "    intersection = tf.reduce_sum(y_true_float * y_pred)\n",
    "    union = tf.reduce_sum(y_true_float) + tf.reduce_sum(y_pred) - intersection\n",
    "    return 1 - (intersection + smooth) / (union + smooth)\n",
    "\n",
    "\n",
    "def dice_loss_simple(y_true, y_pred, smooth=1e-7):\n",
    "    \"\"\"Dice loss function for a single image.\"\"\"\n",
    "\n",
    "    # Formula:\n",
    "    # Dice = (2*|X & Y|)/ (|X|+ |Y|) (different from IOU as the denominator counts |X| twice)\n",
    "\n",
    "    # Non optimal but easy to understand version:\n",
    "    # true_pos = tf.reduce_sum(y_true * y_pred)\n",
    "    # false_pos = tf.reduce_sum(y_pred) - true_pos\n",
    "    # false_neg = tf.reduce_sum(y_true) - true_pos\n",
    "    # return 1 - (2 * true_pos + smooth) / (2 * true_pos + false_pos + false_neg + smooth)\n",
    "\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    assert y_true.dtype == bool\n",
    "\n",
    "    # convert to float\n",
    "    y_true_float = tf.cast(y_true, tf.float32)\n",
    "\n",
    "    intersection = tf.reduce_sum(y_true_float * y_pred)\n",
    "    union_double_count = tf.reduce_sum(y_true_float) + tf.reduce_sum(y_pred)\n",
    "    return 1 - (2 * intersection + smooth) / (union_double_count + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_totals = 0.0\n",
    "iou_totals = 0.0\n",
    "binary_crossentropy_totals = 0.0\n",
    "\n",
    "for test_index in test_indexes:\n",
    "\n",
    "    # Load image and mask\n",
    "    image = np.load(data_dir / f\"image_{test_index}.npy\")\n",
    "    mask = np.load(data_dir / f\"mask_{test_index}.npy\")\n",
    "\n",
    "    # Resize the image and mask to the model image size\n",
    "    pil_image = Image.fromarray(image)\n",
    "    pil_image = pil_image.resize((512, 512))\n",
    "    image = np.array(pil_image).astype(np.float32)\n",
    "    pil_mask = Image.fromarray(mask)\n",
    "    pil_mask = pil_mask.resize((512, 512))\n",
    "    mask = np.array(pil_mask).astype(bool)\n",
    "\n",
    "    # Add batch dimension\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    mask = np.expand_dims(mask, axis=0)\n",
    "    # Add channel dimension\n",
    "    image = np.expand_dims(image, axis=-1)\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "\n",
    "    # Predict the mask\n",
    "    predicted_mask = model.predict(image)\n",
    "\n",
    "    # Remove the batch dimension\n",
    "    predicted_mask = np.squeeze(predicted_mask, axis=0)\n",
    "    mask = np.squeeze(mask, axis=0)\n",
    "    # Remove the channel dimension\n",
    "    predicted_mask = np.squeeze(predicted_mask, axis=-1)\n",
    "    mask = np.squeeze(mask, axis=-1)\n",
    "\n",
    "    # Calculate the dice loss\n",
    "    dice_loss_value = dice_loss_simple(mask, predicted_mask)\n",
    "    dice_totals += dice_loss_value\n",
    "\n",
    "    # Calculate the iou loss\n",
    "    iou_loss_value = iou_loss_simple(mask, predicted_mask)\n",
    "    iou_totals += iou_loss_value\n",
    "\n",
    "    # Calculate the binary crossentropy loss\n",
    "    binary_crossentropy_loss_value = 1 - tf.reduce_mean(\n",
    "        tf.keras.losses.binary_crossentropy(\n",
    "            mask.astype(np.float32), predicted_mask.astype(np.float32), from_logits=True\n",
    "        )\n",
    "    )\n",
    "    binary_crossentropy_totals += binary_crossentropy_loss_value.numpy()\n",
    "\n",
    "    print(\n",
    "        f\"Index {test_index} Losses: dice: {dice_loss_value}, iou: {iou_loss_value}, binary_crossentropy: {binary_crossentropy_loss_value}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Calculate the average losses\n",
    "average_dice_loss = dice_totals / test_size\n",
    "average_iou_loss = iou_totals / test_size\n",
    "average_binary_crossentropy_loss = binary_crossentropy_totals / test_size\n",
    "\n",
    "print(\n",
    "    f\"Average Losses: dice: {average_dice_loss}, iou: {average_iou_loss}, binary_crossentropy: {average_binary_crossentropy_loss}\"\n",
    ")\n",
    "print(\n",
    "    f\"Average Scores: dice: {1 - average_dice_loss}, iou: {1 - average_iou_loss}, binary_crossentropy: {1 - average_binary_crossentropy_loss}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "catsnet-dvc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
